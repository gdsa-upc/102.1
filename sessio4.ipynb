{
 "metadata": {
  "name": "",
  "signature": "sha256:464c542d5bb2aaa73952a4de39d838e0015ebb14800e5d7730a90c16d20684a6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Sessi\u00f3 4"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Creaci\u00f3 de l'esquelet del nostre Building-Recognizer"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Aquesta setmana hem programat les bases del que ser\u00e0 el nostre projecte.\n",
      "Est\u00e0 dividit en 6 funcions: build database, feature extraction, ranking, ranking evaluation, classification i classification evaluation."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Build database"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "build_database.py te la funci\u00f3 de crear un fitxer de text amb les id's a partir de les dades que tenim."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os # llibreria os per poder accedir al directori de treball\n",
      "def build_database(dir_entrada,val_or_train,dir_sortida):\n",
      "    images = os.listdir(dir_entrada) #Llegim el nom dels fitxers que hi ha en el directori que volem (el d'entrada)\n",
      "    outfile = open(dir_sortida+'/outfile_'+val_or_train+'.txt','w') # Creem un fitxer per guardar les id's  \n",
      "    for file in images:\n",
      "        outfile.write(file[0:-4]+\"\\n\") #cada linea del nou fitxer ser\u00e0 el nom de les imatge que hi ha en el directori menys l'extensio .jpg\n",
      "\n",
      "ruta = os.path.dirname(os.path.abspath(__file__)) #ruta absoluta del projecte   \n",
      "build_database(ruta+'/TerrassaBuildings900/train/images',\"train\",ruta+'/files'); #creacio train database\n",
      "build_database(ruta+'/TerrassaBuildings900/val/images',\"val\",ruta+'/files'); #creacio val database"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "L'output de la funci\u00f3 serien dos fitxers .txt un per train i un altre per val amb el format seguent:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "10746-4356-24457\n",
      "10956-21869-28493\n",
      "11072-19559-2960\n",
      "11088-24299-26324\n",
      "11485-2695-23379\n",
      "11776-28585-22785\n",
      "11783-18760-3162\n",
      "1186-2911-12546\n",
      "11929-2134-25457\n",
      "11962-11431-11239\n",
      "12201-19278-27341\n",
      "12297-2961-2691\n",
      "12678-16441-5334\n",
      "..."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Image descriptors"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "get_features.py te la funci\u00f3 de donat un directori amb imatges i un text amb les ID's(build_database) ens crea un diccionari en que la KEY ser\u00e0 l'ID de la imatge i aix\u00f2 anir\u00e0 associat amb un vector de tamany 100 que de moment estar\u00e0 omplert amb n\u00fameros aleatoris"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pickle\n",
      "import os #carreguem la llibreria os per tal d'obtenir la ruta absoluta de la carpeta del projecte\n",
      "\n",
      "ruta = os.path.dirname(os.path.abspath(__file__)) #obtenim la ruta absoluta de la carpeta del projecte\n",
      "\n",
      "def getfeatures(val_or_train):\n",
      "    IDs_file = open(ruta+\"/files/outfile_\"+val_or_train+\".txt\", 'r') #obrim l'arxiu que cont\u00e9 les ids de les imatges\n",
      "    features_file = open(ruta + \"/files/features_\"+val_or_train+\".p\",'w') #obrim l'arxiu en el que escriurem les caracteristiques\n",
      "    feat_vec = dict() #inicialitzem el diccionari buit\n",
      "    for line in IDs_file:\n",
      "        features = np.random.rand(1,100)#Generem el vector de caracteristiques aleatori\n",
      "        final = line.index(\"\\n\") #obtenim la posici\u00f3 del salt de l\u00ednia\n",
      "        feat_vec[line[0:final]] = features #afegim el vector de caracteristiques aleatori al diccionari\n",
      "    IDs_file.close() #tanquem l'arxiu que cont\u00e9 nom\u00e9s les ids de les imatges\n",
      "    pickle.dump(feat_vec, features_file) #escribim el diccionari amb pickle\n",
      "    features_file.close() #tanquem l'arxiu del diccionari\n",
      "getfeatures(\"train\") #cridem a la funcio en mode train\n",
      "getfeatures(\"val\") #cridem a la funci\u00f3 en mode val"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "L'output d'aquesta funci\u00f3 es un archiu .p el qual hem creat amb l'ajuda de la llibreria pickle."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Ranking"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "rank.py a partir del diccionari de caracter\u00edstiques creat per la funci\u00f3 get_features, ens crea un fitxer .txt per cada key del diccionari de validaci\u00f3 o de test (en aquest cas nom\u00e9s de validaci\u00f3)en el que de moment l'ordre ser\u00e0 aleatori."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import pickle #carreguem la llibreria pickle per poder treballar amb els diccionaris\n",
      "import random #carreguem la llibreria que utilitzarem per fer el r\u00e0nking aleatori de cada fitxer.\n",
      "\n",
      "def rank(features_path,save_path,features_train,val_or_test):\n",
      "    featuresfile = open(features_path+'/features_'+val_or_test+'.p','r') #obrim el diccionari de vectors de caracter\u00edstiques de validaci\u00f3 o de test\n",
      "    train_featuresfile = open(features_train,'r') #obrim el diccionari de vectors de caracter\u00edstiques d'entrenament\n",
      "    rankfiles = pickle.load(featuresfile) #carreguem el diccionari validaci\u00f3 o test\n",
      "    train = pickle.load(train_featuresfile) #carreguem el diccionari entrenament\n",
      "    for k in rankfiles.keys(): #per cada clau del diccionari dels vectors de caracteristiques de validaci\u00f3\n",
      "                                #o test ens crear\u00e0 un fitxer .txt guardat a la seva carpeta corresponent,\n",
      "                                #el qual tindr\u00e0 el r\u00e0nking aleatori de les claus del diccionari d'entrenament\n",
      "        outfile = open(save_path+'/ranking_'+val_or_test+'/'+k+'.txt','w') #obrim un fitxer per cada clau del diccionari\n",
      "        ranking = open(save_path+'/ranking_'+val_or_test+'/ranking.txt','w') #obrim un fitxer amb el qual anirem controlant que quan elegim una id d'entrenament aleatoriament,\n",
      "                                                                            #no es torni a repetir en la mateixa clau de validaci\u00f3 o test.\n",
      "                                                                    # Al final del programa s'hauran obert i esborrat tants fitxers ranking com el n\u00famero de claus del diccionari de validaci\u00f3 o entrenament.\n",
      "        for k in train.keys():\n",
      "            ranking.write(k+\"\\n\") #Escribim en el fitxer ranking les claus del diccionari d'entrenament\n",
      "        ranking.close()\n",
      "        for k in train.keys():\n",
      "            ran = random.choice(open(save_path+'/ranking_'+val_or_test+'/ranking.txt').readlines()) #elegim una id del fitxer ranking aleatoriament\n",
      "            outfile.write(ran) #escribim aquesta id aleatoria al fitxer de sortida de la clau de validacio o test que estem treballant\n",
      "            ranking = open(save_path+'/ranking_'+val_or_test+'/ranking.txt','r')\n",
      "            for linea in ranking:\n",
      "                if ran in linea:\n",
      "                    linea.replace(ran,'') #esborrem la linea on es troba la id escollida aleatoriament per assegurarnos que nos es torni a repetir en la clau que estem treballant\n",
      "            ranking.close() #tanquem fitxer de control\n",
      "            \n",
      "        outfile.close() #tanquem fitxer de sortida\n",
      "        os.remove(save_path+'/ranking_'+val_or_test+'/ranking.txt')# esborrem el fitxer de control per la clau en la qual estem treballant\n",
      "    featuresfile.close() #tanquem diccionari validaci\u00f3 o test\n",
      "    train_featuresfile.close() #tanquem diccionari d'entrenament\n",
      "\n",
      "ruta = os.path.dirname(os.path.abspath(__file__)) #ruta absoluta del projecte\n",
      "rank(ruta+'/files',ruta+'/files',ruta+'/files/features_train.p',\"val\") #crida a la funci\u00f3 rank pel diccionari de validaci\u00f3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "L'output ser\u00e0n una serie d'arxius .txt amb el seg\u00fcent format:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "14688-12819-23815\n",
      "8102-608-557\n",
      "17469-21378-15783\n",
      "15716-25710-4269\n",
      "22707-18292-31031\n",
      "10965-12763-11660\n",
      "211-18679-31286\n",
      "2593-20393-27590\n",
      "12487-11017-3187\n",
      "..."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "classify.py a partir del diccionari de caracter\u00edstiques creat per la funci\u00f3 get_features, i d'un txt amb les possibles labels ens retorna un .txt amb les ID's classificades."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os #carreguem la llibreria os per tal d'obtenir la ruta absoluta de la carpeta del projecte\n",
      "import random #carreguem la llibreria d'aleatori\n",
      "import pickle\n",
      "\n",
      "ruta = os.path.dirname(os.path.abspath(__file__)) #obtenim la ruta absoluta de la carpeta del projecte\n",
      "\n",
      "def classify(features,save_to,labels):\n",
      "    infile_features = open(features,'r') #obrim el fitxer on estan les features\n",
      "    #infile_labels = open(labels,'r') #obrim el fitxer on estan les possibles labels\n",
      "    outfile = open(save_to+'/classification.txt', 'w'); #Creem un fitxer on guardar les classificacions\n",
      "    outfile.write(\"ImageID\" \"\\t\" \"ClassID\" \"\\n\")\n",
      "    features = pickle.load(infile_features)\n",
      "    \n",
      "    for k in features.keys():\n",
      "        outfile.write(k + \"\\t\" + random.choice(open(labels).readlines()))\n",
      "    outfile.close()\n",
      "    \n",
      "classify(ruta+'/files/features_train.p',ruta+\"/files\", ruta+\"/files/labels.txt\"); #crida a funci\u00f3 random_classification."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "L'output ser\u00e0 un .txt amb un format de \"ID   Label\" com el seg\u00fcent:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "ImageID\tClassID\n",
      "18339-31531-15817\testacio_nord\n",
      "12487-11017-3187\tteatre_principal\n",
      "12628-28165-25479\tfarmacia_albinyana\n",
      "24970-14942-21710\tajuntament\n",
      "30042-22591-15462\tmercat_independencia\n",
      "23706-19407-15700\tmercat_independencia\n",
      "..."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Ranking Evaluation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "evaluate_ranking.py a partir de els .txt de ranking i del .txt de ground truth ens dona l'average precision i el mean average precision, hem utilitzat les llibreries d'sklearn.metrics per fer aquestes operacions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Aqu\u00ed ir\u00e1 el c\u00f3digo de ranking evaluation\n",
      "\n",
      "COPIADLO SIN EJECUTARLO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "L'output ser\u00e0 un txt amb els resultats amb el seg\u00fcent format:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "COPIAD AQU\u00cd DIRECTAMENTE UN TROCITO DE RESPUESTA."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Classification Evaluation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "evaluate_classification.py a partir del .txt d'anotacions autom\u00e0tiques i del ground truth ens dona els seg\u00fcents par\u00e0metres: Accuracy, Precision / Recall / F1-score, Averaged Precision / Recall / F1-score i la matriu de confusi\u00f3."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Aqui ira el codigo de classification evaluation\n",
      "\n",
      "COPIADLO SIN EJECUTARLO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "L'output ser\u00e0...."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "COPIAD AQU\u00cd DIRECTAMENTE UN TROCITO DE RESPUESTA."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}